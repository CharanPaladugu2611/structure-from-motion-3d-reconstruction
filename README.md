# ğŸ§  Structure from Motion

Turn 2D images into a 3D world â€” no LiDAR, no depth camera, just pure computer vision.
In this project, we implemented a complete Structure from Motion (SfM) pipeline using a series of 14 photos of a scene taken from different viewpoints. The system automatically matches features across images, estimates camera poses, triangulates points in 3D space, and refines everything using bundle adjustment â€” resulting in a sparse but accurate 3D reconstruction of the scene.
This classical multi-view geometry project showcases the power of camera intrinsics, linear algebra, and some well-placed RANSAC

---

## ğŸ› ï¸ Core Pipeline

- Feature Matching
  * SIFT feature detection across all image pairs
  * Loweâ€™s ratio test for robust matching
- Fundamental Matrix Estimation
  * Estimated using the 8-point algorithm
  * RANSAC used to filter outliers
- Essential Matrix & Pose Recovery
  * Compute essential matrix using camera intrinsics
  * Decompose to recover R, t (relative pose)
  * Apply cheirality check to ensure triangulated points lie in front of both cameras
- Triangulation
  * Linear triangulation of point correspondences to get 3D locations
- PnP Pose Estimation
  * For subsequent images, apply Perspective-n-Point to recover pose
  * Refined using Non-Linear PnP
- Bundle Adjustment
  * Jointly optimize camera parameters and 3D point positions
  * Minimizes reprojection error using non-linear least squares

---

## ğŸ” Results
âœ… Sparse 3D reconstruction of a book/object captured from 14 different angles
âœ… Visualized 3D point cloud and camera trajectory
âœ… Exported .ply file viewable in Meshlab or Open3D
âœ… Verified accuracy through reprojection checks
### ğŸ“· Sample Output
![image](https://github.com/user-attachments/assets/4b8b0a1f-88de-47f8-8202-609d312de3f0)
![image](https://github.com/user-attachments/assets/3179bb62-a6b7-471a-8b31-154e134b102b)

---

## ğŸ§± System Architecture
```
Input Images (14)
        â†“
SIFT Keypoints & Descriptors
        â†“
Feature Matching â†’ Fundamental Matrix Estimation (RANSAC)
        â†“
Essential Matrix â†’ Camera Pose Recovery
        â†“
Triangulation â†’ Initial 3D Points
        â†“
Incremental Pose Estimation using PnP (Linear â†’ RANSAC â†’ Nonlinear)
        â†“
Bundle Adjustment Optimization
        â†“
Export .ply â†’ 3D Point Cloud Visualization
```

---

## âš™ï¸ Tools & Technologies
- Python

- OpenCV (SIFT, feature matching, triangulation)

- NumPy, SciPy

- Matplotlib (intermediate plotting)

- Meshlab (3D visualization of ```.ply```)

- Custom functions for cheirality, BA, PnP, and matrix manipulation

---

## ğŸ’¡ Key Takeaways
* Classical geometry methods can produce robust 3D reconstructions â€” no deep learning needed

* RANSAC is essential to remove noisy matches for matrix estimation

* Bundle adjustment drastically improves accuracy and visual quality

* Cheirality checks are critical in multi-solution pose estimation

* Visualization of reprojection errors is a great sanity check

---

## ğŸš€ Future Enhancements
* Use ORB or learned descriptors (e.g., SuperPoint) for feature matching

* Integrate COLMAP or OpenMVG for dense reconstruction

* Evaluate reprojection error dynamically across all views

* Extend to video-based SfM with real-time SLAM-like updates

* Try neural rendering using NeRF or BundleFusion as a downstream enhancement

